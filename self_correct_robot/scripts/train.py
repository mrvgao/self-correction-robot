"""
The main entry point for training policies.

Args:
    config (str): path to a config json that will be used to override the default settings.
        If omitted, default settings are used. This is the preferred way to run experiments.

    algo (str): name of the algorithm to run. Only needs to be provided if @config is not
        provided.

    name (str): if provided, override the experiment name defined in the config

    dataset (str): if provided, override the dataset path defined in the config

    debug (bool): set this flag to run a quick training run for debugging purposes    
"""

import argparse
import json
import numpy as np
import time
import os
import shutil
import psutil
import sys
import socket
import traceback

from collections import OrderedDict

import torch
from torch.utils.data import DataLoader

import self_correct_robot
import self_correct_robot.utils.train_utils as TrainUtils
import self_correct_robot.tasl_exp.rollout as RolloutUtils
import self_correct_robot.utils.torch_utils as TorchUtils
import self_correct_robot.utils.obs_utils as ObsUtils
import self_correct_robot.utils.env_utils as EnvUtils
import self_correct_robot.utils.file_utils as FileUtils
import self_correct_robot.utils.lang_utils as LangUtils
from self_correct_robot.config import config_factory
from self_correct_robot.algo import algo_factory, RolloutPolicy
from self_correct_robot.utils.log_utils import PrintLogger, DataLogger, flush_warnings
from self_correct_robot.tasl_exp.reward_model import ValueResNetWithAttnPerformance
from self_correct_robot.utils.load_dataloader import load_dataloader


def train(config, device):
    """
    Train a model using the algorithm.
    """

    (
        train_loader,
        valid_loader,
        eval_env_name_list,
        obs_normalization_stats,
        data_logger,
        obs_normalization_stats,
        action_normalization_stats,
        lang_encoder,
        env_iterator,
        video_dir,
        eval_env_horizon_list,
        vis_dir,
        trainset,
        validset,
        env_meta,
        shape_meta,
        ckpt_dir,
        shape_meta_list
    ) = load_dataloader(config, device)

    # if config.value_model_path:
    #     main_value_model = None
    #     # main_value_model.load_state_dict(torch.load(config.value_model_path))
    #     # main_value_model.to(device)
    #     target_value_model = ValueResNetWithAttnPerformance()
    #     target_value_model.load_state_dict(torch.load(config.value_model_path))
    #     target_value_model.to(device)
    #     target_value_model.eval()
    # else:

    main_value_model = None
    target_value_model = None

    ckpt_path = config.experiment.ckpt_path

    model = algo_factory(
        algo_name=config.algo_name,
        config=config,
        obs_key_shapes=shape_meta_list[0]["all_shapes"],
        ac_dim=shape_meta_list[0]["ac_dim"],
        device=device,
        main_value_model=main_value_model,
        target_value_model=target_value_model,
        # progress_model=progress_model,
    )

    if ckpt_path is not None:
        print("LOADING MODEL WEIGHTS FROM " + ckpt_path)
        from self_correct_robot.utils.file_utils import maybe_dict_from_checkpoint

        ckpt_dict = maybe_dict_from_checkpoint(ckpt_path=ckpt_path, device=device)
        model.deserialize(ckpt_dict["model"])

    print("\n============= Model Summary =============")
    print(model)  # print model summary
    print("")

    # print all warnings before training begins
    print("*" * 50)
    print("Warnings generated by self_correct_robot have been duplicated here (from above) for convenience. Please check them carefully.")
    flush_warnings()
    print("*" * 50)
    print("")

    # main training loop
    best_valid_loss = None
    best_return = {k: -np.inf for k in eval_env_name_list} if config.experiment.rollout.enabled else None
    best_success_rate = {k: -1. for k in eval_env_name_list} if config.experiment.rollout.enabled else None
    last_ckpt_time = time.time()

    # number of learning steps per epoch (defaults to a full dataset pass)
    train_num_steps = config.experiment.epoch_every_n_steps
    valid_num_steps = config.experiment.validation_epoch_every_n_steps

    all_value_embeddings = []

    for epoch in range(0, config.train.num_epochs + 1): # epoch numbers start at 1
        if epoch > 0 and not config.experiment.only_rollout:
            step_log = TrainUtils.run_epoch(
                model=model,
                data_loader=train_loader,
                epoch=epoch,
                num_steps=train_num_steps,
                obs_normalization_stats=obs_normalization_stats,
                config=config,
            )
            model.on_epoch_end(epoch)

            # setup checkpoint path
            epoch_ckpt_name = "model_epoch_{}".format(epoch)

            # check for recurring checkpoint saving conditions
            should_save_ckpt = False
            if config.experiment.save.enabled:
                time_check = (config.experiment.save.every_n_seconds is not None) and \
                    (time.time() - last_ckpt_time > config.experiment.save.every_n_seconds)
                epoch_check = (config.experiment.save.every_n_epochs is not None) and \
                    (epoch > 0) and (epoch % config.experiment.save.every_n_epochs == 0)
                epoch_list_check = (epoch in config.experiment.save.epochs)
                should_save_ckpt = (time_check or epoch_check or epoch_list_check)
            ckpt_reason = None
            if should_save_ckpt:
                last_ckpt_time = time.time()
                ckpt_reason = "time"

            # print("Train Epoch {}".format(epoch))
            # print(step_log, sort_keys=True, indent=4)

            PARAMTERS = 'Parameters'

            for k, v in step_log.items():
                if k.startswith("Time_"):
                    data_logger.record("Timing_Stats/Train_{}".format(k[5:]), v, epoch)
                # elif k.startswith(PARAMTERS):
                #     data_logger.record("{}/{}".format(PARAMTERS, k[len(PARAMTERS):]), v, epoch, data_type='hist')
                    # epoch_value_embedding = np.concatenate(v, axis=0)
                    # all_value_embeddings.append(epoch_value_embedding)
                    # data_logger.record('{}/value_embeddings'.format(PARAMTERS), all_value_embeddings, epoch, data_type='hist')
                else:
                    data_logger.record("Train/{}".format(k), v, epoch)

            # Evaluate the model on validation set
            if config.experiment.validate:
                with torch.no_grad():
                    step_log = TrainUtils.run_epoch(model=model,
                                                    data_loader=valid_loader, epoch=epoch, validate=True,
                                                    num_steps=valid_num_steps, config=config)
                for k, v in step_log.items():
                    if k.startswith("Time_"):
                        data_logger.record("Timing_Stats/Valid_{}".format(k[5:]), v, epoch)
                    else:
                        data_logger.record("Valid/{}".format(k), v, epoch)

                # print("Validation Epoch {}".format(epoch))
                # print(step_log, sort_keys=True, indent=4)

                # save checkpoint if achieve new best validation loss
                valid_check = "Loss" in step_log
                if valid_check and (best_valid_loss is None or (step_log["Loss"] <= best_valid_loss)):
                    best_valid_loss = step_log["Loss"]
                    if config.experiment.save.enabled and config.experiment.save.on_best_validation:
                        epoch_ckpt_name += "_best_validation_{}".format(best_valid_loss)
                        should_save_ckpt = True
                        ckpt_reason = "valid" if ckpt_reason is None else ckpt_reason
        else:
            should_save_ckpt = False
            epoch_ckpt_name = "model_epoch_{}".format(epoch)
            ckpt_reason = None

        # Evaluate the model by by running rollouts

        # do rollouts at fixed rate or if it's time to save a new ckpt
        video_paths = None
        rollout_check = (epoch % config.experiment.rollout.rate == 0) #or (should_save_ckpt and ckpt_reason == "time") # remove this section condition, not desired when rollouts are expensive and saving frequent checkpoints
        if config.experiment.rollout.enabled and (epoch > config.experiment.rollout.warmstart) and rollout_check:
            # wrap model as a RolloutPolicy to prepare for rollouts
            rollout_model = RolloutPolicy(
                model,
                obs_normalization_stats=obs_normalization_stats,
                action_normalization_stats=action_normalization_stats,
                lang_encoder=lang_encoder,
            )

            num_episodes = config.experiment.rollout.n
            all_rollout_logs, video_paths = RolloutUtils.rollout_with_stats(
                policy=rollout_model,
                envs=env_iterator(),
                horizon=eval_env_horizon_list,
                use_goals=config.use_goals,
                num_episodes=num_episodes,
                render=False,
                video_dir=video_dir if config.experiment.render_video else None,
                epoch=epoch,
                video_skip=config.experiment.get("video_skip", 5),
                terminate_on_success=config.experiment.rollout.terminate_on_success,
                del_envs_after_rollouts=True,
                data_logger=data_logger,
                config=config,
                device=device,
                value_model=target_value_model,
                with_progress_correct=config.experiment.rollout.with_progress_correct,
            )

            #### move this code to rollout_with_stats function to log results one by one ####
            # # summarize results from rollouts to tensorboard and terminal
            # for env_name in all_rollout_logs:
            #     rollout_logs = all_rollout_logs[env_name]
            #     for k, v in rollout_logs.items():
            #         if k.startswith("Time_"):
            #             data_logger.record("Timing_Stats/Rollout_{}_{}".format(env_name, k[5:]), v, epoch)
            #         else:
            #             data_logger.record("Rollout/{}/{}".format(k, env_name), v, epoch, log_stats=True)

            #     print("\nEpoch {} Rollouts took {}s (avg) with results:".format(epoch, rollout_logs["time"]))
            #     print('Env: {}'.format(env_name))
            #     print(json.dumps(rollout_logs, sort_keys=True, indent=4))

            # checkpoint and video saving logic
            updated_stats = RolloutUtils.should_save_from_rollout_logs(
                all_rollout_logs=all_rollout_logs,
                best_return=best_return,
                best_success_rate=best_success_rate,
                epoch_ckpt_name=epoch_ckpt_name,
                save_on_best_rollout_return=config.experiment.save.on_best_rollout_return,
                save_on_best_rollout_success_rate=config.experiment.save.on_best_rollout_success_rate,
            )
            best_return = updated_stats["best_return"]
            best_success_rate = updated_stats["best_success_rate"]
            epoch_ckpt_name = updated_stats["epoch_ckpt_name"]
            should_save_ckpt = (config.experiment.save.enabled and updated_stats["should_save_ckpt"]) or should_save_ckpt
            if updated_stats["ckpt_reason"] is not None:
                ckpt_reason = updated_stats["ckpt_reason"]

        # check if we need to save model MSE
        should_save_mse = False
        if config.experiment.mse.enabled:
            if config.experiment.mse.every_n_epochs is not None and epoch % config.experiment.mse.every_n_epochs == 0:
                should_save_mse = True
            if config.experiment.mse.on_save_ckpt and should_save_ckpt:
                should_save_mse = True
        if should_save_mse:
            print("Computing MSE ...")
            if config.experiment.mse.visualize:
                save_vis_dir = os.path.join(vis_dir, epoch_ckpt_name)
            else:
                save_vis_dir = None
            mse_log, vis_log = model.compute_mse_visualize(
                trainset,
                validset,
                num_samples=config.experiment.mse.num_samples,
                savedir=save_vis_dir,
            )    
            for k, v in mse_log.items():
                data_logger.record("{}".format(k), v, epoch)
            
            for k, v in vis_log.items():
                data_logger.record("{}".format(k), v, epoch, data_type='image')


            # print("MSE Log Epoch {}".format(epoch))
            # print(json.dumps(mse_log, sort_keys=True, indent=4))
        
        # # Only keep saved videos if the ckpt should be saved (but not because of validation score)
        # should_save_video = (should_save_ckpt and (ckpt_reason != "valid")) or config.experiment.keep_all_videos
        # if video_paths is not None and not should_save_video:
        #     for env_name in video_paths:
        #         os.remove(video_paths[env_name])

        # Save model checkpoints based on conditions (success rate, validation loss, etc)
        if should_save_ckpt:    
            TrainUtils.save_model(
                model=model,
                config=config,
                env_meta=env_meta,
                shape_meta=shape_meta,
                ckpt_path=os.path.join(ckpt_dir, epoch_ckpt_name + ".pth"),
                obs_normalization_stats=obs_normalization_stats,
                action_normalization_stats=action_normalization_stats,
            )

        # Finally, log memory usage in MB
        process = psutil.Process(os.getpid())
        mem_usage = int(process.memory_info().rss / 1000000)
        data_logger.record("System/RAM Usage (MB)", mem_usage, epoch)
        print("\nEpoch {} Memory Usage: {} MB\n".format(epoch, mem_usage))

    # terminate logging
    data_logger.close()


def main(args):

    if args.config is not None:
        ext_cfg = json.load(open(args.config, 'r'))
        config = config_factory(ext_cfg["algo_name"])
        # update config with external json - this will throw errors if
        # the external config has keys not present in the base algo config
        with config.values_unlocked():
            config.update(ext_cfg)
    else:
        config = config_factory(args.algo)

    if args.dataset is not None:
        config.train.data = args.dataset

    if args.name is not None:
        config.experiment.name = args.name

    # get torch device
    device = TorchUtils.get_torch_device(try_to_use_cuda=config.train.cuda, cuda_mark=config.cuda_mark)

    # maybe modify config for debugging purposes
    if args.debug:
        # shrink length of training to test whether this run is likely to crash
        config.unlock()
        config.lock_keys()

        # train and validate (if enabled) for 3 gradient steps, for 2 epochs
        config.experiment.epoch_every_n_steps = 3
        config.experiment.validation_epoch_every_n_steps = 3
        config.train.num_epochs = 2

        # if rollouts are enabled, try 2 rollouts at end of each epoch, with 10 environment steps
        config.experiment.rollout.rate = 1
        config.experiment.rollout.n = 2
        config.experiment.rollout.horizon = 10

        # send output to a temporary directory
        config.train.output_dir = "/tmp/tmp_trained_models"

    # lock config to prevent further modifications and ensure missing keys raise errors
    config.lock()

    # catch error during training and print it
    res_str = "finished run successfully!"
    try:
        train(config, device=device)
    except Exception as e:
        res_str = "run failed with error:\n{}\n\n{}".format(e, traceback.format_exc())
    print(res_str)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # External config file that overwrites default config
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="(optional) path to a config json that will be used to override the default settings. \
            If omitted, default settings are used. This is the preferred way to run experiments.",
    )

    # Algorithm Name
    parser.add_argument(
        "--algo",
        type=str,
        help="(optional) name of algorithm to run. Only needs to be provided if --config is not provided",
    )

    # Experiment Name (for tensorboard, saving models, etc.)
    parser.add_argument(
        "--name",
        type=str,
        default=None,
        help="(optional) if provided, override the experiment name defined in the config",
    )

    # Dataset path, to override the one in the config
    parser.add_argument(
        "--dataset",
        type=str,
        default=None,
        help="(optional) if provided, override the dataset path defined in the config",
    )

    # debug mode
    parser.add_argument(
        "--debug",
        action='store_true',
        help="set this flag to run a quick training run for debugging purposes"
    )

    args = parser.parse_args()
    main(args)
